# 한국어 트랜스포머 챗봇 프로젝트

![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.6+-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

트랜스포머 아키텍처를 활용한 한국어 대화형 챗봇 구현 프로젝트입니다. 이 프로젝트는 한국어 대화 데이터셋을 사용하여 기본적인 대화가 가능한 챗봇을 구현하고, 이를 게임 형태로 확장한 **"Bot야 말해봐!"** 게임 개발의 기반이 됩니다.

## 목차

- [프로젝트 개요](#프로젝트-개요)
- [데이터셋](#데이터셋)
- [기술적 구현](#기술적-구현)
- [모델 성능](#모델-성능)
- [학습 경험 및 고찰](#학습-경험-및-고찰)
- [발전 프로젝트: Bot야 말해봐!](#발전-프로젝트-bot야-말해봐)
- [설치 및 실행 방법](#설치-및-실행-방법)
- [향후 계획](#향후-계획)

## 프로젝트 개요

이 프로젝트는 트랜스포머 아키텍처를 활용하여 한국어 대화가 가능한 챗봇을 구현했습니다. 트랜스포머는 어텐션 메커니즘을 기반으로 한 강력한 시퀀스-투-시퀀스 모델로, 자연어 처리 분야에서 뛰어난 성능을 보입니다.

주요 특징:
- 멀티헤드 어텐션 메커니즘
- 포지셔널 인코딩
- SubwordTextEncoder를 활용한 한국어 토큰화
- 체크포인트 기반 모델 저장 및 복원
- TFLite 모델 변환을 통한 모바일 배포 준비

## 데이터셋

본 프로젝트에서는 [송영숙님의 챗봇 데이터](https://github.com/songys/Chatbot_data)를 사용했습니다. 이 데이터셋은 질문과 답변 쌍으로 구성되어 있으며, 한국어 대화 데이터를 포함하고 있습니다.

```
데이터 통계:
- 총 11,876개의 질문-답변 쌍
- 훈련 데이터: 9,500개
- 검증 데이터: 2,376개
```

## 기술적 구현

### 모델 아키텍처

트랜스포머 모델의 주요 컴포넌트:

1. **인코더**: 입력 시퀀스를 처리
   - 포지셔널 인코딩
   - 멀티헤드 셀프 어텐션
   - 피드포워드 네트워크

2. **디코더**: 출력 시퀀스 생성
   - 마스크드 멀티헤드 어텐션
   - 인코더-디코더 어텐션
   - 피드포워드 네트워크

3. **토큰화**: SubwordTextEncoder 사용
   - 형태소 분석기 대신 데이터 기반 토큰화
   - OOV(Out-of-Vocabulary) 문제 해결

### 학습 과정

```python
# 주요 하이퍼파라미터
NUM_LAYERS = 4
D_MODEL = 256
NUM_HEADS = 8
UNITS = 512
DROPOUT = 0.1
EPOCHS = 20
BATCH_SIZE = 64
```

- 학습률 스케줄링: Custom Learning Rate Scheduler 사용
- 손실 함수: SparseCategoricalCrossentropy
- 체크포인트: 각 에폭마다 모델 가중치 저장

### 모델 변환

TensorFlow SavedModel 형식으로 저장 후 TFLite로 변환하여 모바일 환경에서 실행 가능하도록 했습니다.

## 모델 성능
- 긍정적인 지표:
    - 손실(loss)이 초기 약 2.5에서 최종 0.1576으로 크게 감소했습니다
    - 20 에폭 동안 꾸준히 개선되는 추세를 보였습니다
    - 마지막 에폭에서도 손실이 여전히 감소하고 있어 학습이 잘 진행됨을 나타냅니다

- 고려할 점:
    - 정확도(accuracy)가 26.80%로 낮아 보일 수 있으나, 언어 생성 작업에서는 예상된 결과입니다
    - 어휘 크기가 큰 토큰 예측에서는 정확한 토큰 일치보다 의미적 일관성이 더 중요합니다

- 학습률 관찰:
    - 에폭 19에서 0.00069에서 에폭 20에서 0.00073으로 약간 증가했습니다
    - 이는 사용자 정의 학습률 스케줄러가 적절히 작동하고 있음을 보여줍니다

![image](https://github.com/user-attachments/assets/877ef6a9-8f82-43e6-bf65-8da706ff26f0)

## 학습 경험 및 고찰

### 배운 점
- 트랜스포머 모델의 구조(인코더-디코더, 멀티헤드 어텐션, 포지셔널 인코딩)를 실제로 구현하며 원리를 깊이 이해
- 한국어 자연어 처리에서 형태소 분석기 대신 SubwordTextEncoder를 활용하는 방법과 그 장단점 파악
- 체크포인트 시스템을 통한 효율적인 모델 학습 및 관리 방법
- 딥러닝 모델의 학습-배포 파이프라인의 전체 과정 경험

### 아쉬운 점
- 데이터셋의 크기와 다양성 부족으로 챗봇의 대화 성능에 한계
- TFLite 변환 과정에서 복잡한 트랜스포머 모델의 최적화 어려움
- 모델 하이퍼파라미터 튜닝을 충분히 하지 못한 점
- 더 다양한 한국어 특성(존댓말, 방언 등)을 학습시키지 못한 것

### 어려웠던 점
- 복잡한 모델 구조로 인한 디버깅 과정의 어려움
- TensorFlow 에러 해석과 해결(특히 타입 에러, 모델 구축 관련 문제)
- 학습 과정에서의 메모리 문제와 성능 최적화
- TFLite 변환 시 dynamic shape 처리와 같은 기술적 제약

## 발전 프로젝트: Bot야 말해봐!

### 서비스 개요

![image](https://github.com/user-attachments/assets/6a8a3438-7425-43b9-93ed-e75031b51720)

본 서비스는  챗봇의 동문서답 특성을 게임화한 소셜 추리 게임입니다. 플레이어들은 챗봇의 엉뚱한 답변을 보고 원래 질문을 추측하는 과정에서 재미와 웃음을 경험합니다.

#### 핵심 가치
- **단순함**: 누구나 쉽게 이해하고 즐길 수 있는 게임성
- **유머**: 예측불가능한 챗봇 응답이 주는 웃음
- **소셜**: 친구들과 함께 즐기는 파티 게임으로 활용 가능

### 기술 구현 계획

#### 필요 기술 스택
- Flutter (크로스 플랫폼 앱 개발)
- TFLite 모델 통합
- 간단한 점수 관리 시스템 (로컬 저장소 활용)

#### 주요 기능 모듈
1. **챗봇 엔진 모듈**: TFLite 모델 로드 및 추론 처리
2. **게임 로직 모듈**: 질문 입력, 응답 표시, 추측 처리
3. **UI 모듈**: 게임 화면, 스코어보드, 타이머 등
4. **데이터 관리 모듈**: 간단한 질문-응답 기록, 점수 저장

### 게임 플로우

#### 기본 게임 모드
1. 플레이어들이 모여 앱 시작
2. 질문자 선정 (첫 라운드는 앱 소유자)
3. 질문자가 비밀리에 챗봇에게 질문 입력
4. 챗봇의 응답을 모든 플레이어에게 공개
5. 타이머 시작 (30초)
6. 다른 플레이어들이 원래 질문 추측
7. 가장 근접한 추측에 점수 부여
8. 역할을 바꿔 다음 라운드 진행

#### 확장 게임 모드 (예정)
- **시간 도전 모드**: 제한 시간 내 최대한 많은 질문 맞추기
- **테마 모드**: 특정 주제에 관한 질문만 허용

### UI/UX 설계

#### 주요 화면
1. **시작 화면**: 게임 타이틀, 시작 버튼, 간단한 규칙 설명
2. **플레이어 설정**: 참가자 이름 입력 (2-8명)
3. **게임 화면**:
   - 질문 입력 영역 (질문자만 볼 수 있음)
   - 챗봇 응답 표시 영역
   - 추측 입력 영역
   - 타이머 및 스코어보드
4. **결과 화면**: 라운드 종료 후 결과 및 점수 표시

#### 디자인 방향
- 심플하고 직관적인 UI
- 밝고 재미있는 색상 팔레트
- 챗봇 캐릭터를 활용한 친근한 분위기

## 설치 및 실행 방법

### 요구 사항
- Python 3.7+
- TensorFlow 2.6+
- pandas, numpy, matplotlib
- (게임 앱) Flutter SDK


## 향후 계획

1. **모델 개선**
   - 더 큰 규모의 한국어 대화 데이터셋 활용
   - BERT, GPT 등 최신 모델 아키텍처 적용 실험
   - 더 효율적인 토큰화 방법 연구

2. **게임 기능 확장**
   - 다양한 게임 모드 추가
   - 온라인 멀티플레이어 기능
   - 리더보드 및 업적 시스템

3. **UI/UX 개선**
   - 사용자 피드백 기반 인터페이스 개선
   - 챗봇 캐릭터 애니메이션 추가
   - 다국어 지원

## 학습 경험 및 고찰

### 전승아 회고: 
- 배운 점
    - 트랜스포머 모델의 구조(인코더-디코더, 멀티헤드 어텐션, 포지셔널 인코딩)를 실제로 구현하며 원리를 깊이 이해할 수 있었음
    - 한국어 자연어 처리에서 형태소 분석기 대신 SubwordTextEncoder를 활용하는 방법과 그 장단점 파악

- 아쉬운 점
    - 데이터셋의 크기와 다양성 부족으로 챗봇의 대화 성능에 한계가 있음
    - TFLite 변환 과정에서 복잡한 트랜스포머 모델의 최적화 어려움

- 느낀 점
    - 트랜스포머 모델이 시퀀스 데이터 처리에 얼마나 강력한지 체감했음
    - 실제 구현과 이론 간의 간극을 메우는 과정에서 많은 학습 발생
    - 케창딥에서 봤던 내용을 실습으로 정리. 

- 어려웠던 점
    - 자잘한 오류 해결, 한국어 형태소 변환의 문제. 

### 이하은 회고: 
- 배운 점 : 
    - 트랜스포머 전반적인 구조 및 인코더, 디코더 부분이 어떠한 역할을 하는지를 알게되었고, 챗봇을 만들기 위해 플러우를 알게되었다. 특히 한국어 대회 데이터셋으로 학습 진행 시 데이터의 전처리 부분이 영문으로 학습할 때의 전처리와 조금 다르다는 것을 배웠다.
- 아쉬운 점 : 
    - 트랜스포머 모델이 이전에 다뤘던 모델보다 복잡하다보니 모든 코드를 이해하고 넘어갈 수 없었다. 코드를 읽는 실력 열심히 키워야겠다.
- 느낀 점 : 
    - 스마트한 챗봇을 만드는 것이 진짜 쉬운일이 아니고 GPT와 같은 다양한 기능을 수행할 수 있는 LLM 모델은 또한 얼마나 복잡한 코드로 구성되어 있는지 상상만해도 눈앞이 캄캄하다...
- 여려웠던 점 : 
    - 중간 중간 발생하는 에러들을 바로 잡는데 코드 전체가 너무 길기도 하고 복잡하기도 해서 쉽게쉽게 해결되지 않았다. 기존에 있는 노드 9번 코드를 재활용 했으면 조금 더 수월했을 지도 모른다. 잘 모르는 부분에서는 조금조금씩 알아가는 것이 좋고 급발진하다가 길을 잃게 된다.
 
## 라이센스

이 프로젝트는 MIT 라이센스 하에 배포됩니다. 자세한 내용은 LICENSE 파일을 참조하세요.

## 감사의 말

- 챗봇 데이터를 제공해주신 송영숙님께 감사드립니다.
- 본 프로젝트는 교육 목적으로 개발되었습니다.

