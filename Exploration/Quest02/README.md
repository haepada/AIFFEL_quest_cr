## 📘 **전체 실험 개요 및 요약**

### 🔍 **실험 목적**
> 뉴스 기사 데이터를 기반으로 **추상적 요약(Seq2Seq 모델)**과 **추출적 요약(Summa)**을 비교하고, 다양한 자동화 지표(BLEU, ROUGE)와 **키워드 기반 평가 방식**을 통해 모델 성능을 다각도로 분석한다.

---

### 🧱 **실험 구성**

| 단계 | 내용 |
|------|------|
| **1️⃣ 데이터 준비** | 뉴스 기사 원문(`text`)과 정답 요약(`headlines`)을 포함한 데이터셋 확보 |
| **2️⃣ 데이터 전처리 (추상적 요약용)** | - 텍스트 정제 및 정규화<br>- 단어 수 제한, 토크나이징, 희귀 단어 제거 등<br>- 희귀 단어 비율, 등장 빈도 시각화로 Threshold 선정 |
| **3️⃣ 어텐션 메커니즘 적용 모델 구현** | - Seq2Seq + Attention 모델 구성<br>- LSTM 기반 인코더-디코더에 어텐션 레이어 통합 |
| **4️⃣ 실제 결과와 정답 요약 비교** | - 추상적 요약 생성 후, 정답 요약과 비교<br>- BLEU, ROUGE-L 등 **정량적 평가** 수행 |
| **5️⃣ Summa(TextRank)로 추출적 요약 수행** | - 전처리 없이 원문을 입력으로 사용<br>- 핵심 문장 자동 추출하여 요약 생성 |
| **6️⃣ 추상 vs 추출 요약 비교** | - BLEU/ROUGE 정량 비교<br>- **Keyword Inclusion / Recall / Content Fidelity**로 내용 보존력 평가<br>- 상위/하위 샘플 비교, 시각화 분석 |
| **7️⃣ 성능 향상을 위한 개선 전략 탐색** | - 모델 개선 전략 제안: Copy Mechanism, Coverage, Beam Search 등<br>- 학습 안정화 기법: Dropout, Gradient Clipping, Scheduler 등 |
| **8️⃣ 회고 및 정리** | - 시행착오: 데이터 인덱스 불일치, 전처리 오류<br>- 학습 성과: 요약 방식별 특성 이해, 다양한 평가 방식 적용 능력 향상 |

---

### ⚠️ **주요 시행착오 및 교훈**

1. **데이터 인덱스 불일치 → 유사도 기반 매칭 필요**
2. **Summa 모델은 전처리 시 성능 하락 → 전처리 생략 필수**
3. **단순 지표 외에도 키워드 기반 평가가 정보 보존 측면에서 효과적**

---

### 🧠 **결과 요약 및 인사이트**

| 모델 | BLEU/ROUGE | 핵심 단어 포함률 | 특이점 |
|------|------------|------------------|--------|
| **Seq2Seq** | BLEU 낮음, ROUGE 일부 ↑ | 키워드 포함률 낮음 | 추상적 문장 생성 능력은 있으나 정보 보존 약함 |
| **Summa** | ROUGE 전반적으로 우수 | 키워드 포함률 높음 | 문장 구성은 투박하지만 정보 보존에 강함 |

> ✅ **추상 요약은 문장 생성력**, **추출 요약은 정보 보존력**  
> → **어플리케이션 목적에 따라 선택 혹은 결합 전략 고려 필요**

---

### 🚀 **향후 개선 방향 (모델 관점)**

- **Copy Mechanism**, **Coverage Attention**, **Keyword-aware Loss** 등 정보 보존력 강화 모델 구조 도입
- **Beam Search**, **Bidirectional LSTM**, **Pre-trained Embedding** 등 정밀도 향상 구조 개선
- **Keyphrase 기반 평가 방식 지속 적용 → 평가 신뢰도 제고**

---
<전승아>
- **✅ 배운 점 (What I Learned)**

1. **Seq2Seq 모델과 어텐션 메커니즘의 구조와 원리**  
   - 기본적인 인코더-디코더 구조를 익혔고, 어텐션을 통해 디코더가 입력 시퀀스의 중요한 부분에 집중할 수 있도록 돕는 방식을 이해함.

2. **BLEU, ROUGE 외에도 다양한 평가 지표가 필요하다는 사실**  
   - 기존 정량 지표(BLEU, ROUGE)는 형식적인 유사도만 반영함 → **핵심 단어 포함 수**, **포함 비율**, **정보 보존 정도** 등을 함께 평가해야 실질적인 성능 확인 가능.

3. **데이터 전처리에서 통계적 기준의 중요성**  
   - 단순히 임의로 자르기보다는 IQR이나 Threshold 기반의 시각화를 통해 **데이터의 특성을 반영한 합리적 기준 설정** 가능함.

4. **추출 요약과 추상 요약의 개념적, 평가적 차이**  
   - 추출 요약은 정보 보존력은 높지만 부자연스럽고, 추상 요약은 표현이 자연스럽지만 정보 손실 위험이 존재함 → **두 방식의 조합이 현실적으로 가장 효과적일 수 있음.**

---

-  **⚠️ 시행착오 (Challenges & Mistakes)**


1. **데이터 인덱스 불일치로 인한 비교 실패**
- 전처리 및 샘플링 과정에서 **Seq2Seq 데이터와 Summa 데이터 간 인덱스가 달라짐**.
- 단순한 인덱스 기준 매칭은 무의미해졌고, 결과적으로 **텍스트 유사도 기반으로 matching 방식을 전환**해야 했음.

2. **Summa 모델은 전처리 없이 사용해야 함**
- Summa는 본질적으로 **비지도 학습 기반의 extractive 요약 모델**.
- 전처리를 적용하면 문장 구조가 무너져 **요약 품질이 급격히 저하**됨.
- → 반면, Seq2Seq은 전처리를 통해 불필요한 노이즈 제거가 필요했음.  
- **모델별 전처리 방식은 달라야 한다는 점**을 명확히 체득하게 된 경험.


-  **😔 아쉬운 점 (What Could Be Improved)**

1. **Beam Search 등의 디코딩 전략 실험 부족**  
   - 대부분 greedy decoding으로만 결과를 봤고, 다양한 디코딩 방식(beam, top-k, nucleus sampling)을 적용해보지 못한 점이 아쉬움.

2. **어텐션 가중치 시각화 미시도**  
   - 어텐션 매커니즘의 해석 가능성을 충분히 활용하지 못함 → attention weight matrix 시각화로 어떤 단어에 주목하는지 보여줄 수 있었음.

3. **추상 요약의 불안정성 보완 필요성**  
   - 일부 추상 요약 결과가 의미 없는 문장으로 나왔고, 이를 걸러낼 후처리 로직이나 `coverage`, `copy mechanism` 등 개선을 적용하지 못한 점.


  
<윤순천>

-  배운 점
추출적 요약은 (구두점이 살아 있는) 원문을 대상으로 할 때 가능하다.
짧은 원문을 요약할 때 고려해야 할 점이 많다. (추출시 ratio, 요약실패 시 문법오류로 판단할지 안할지 등)

-  아쉬운 점
코딩하면서 생성된 변수와 컬럼 수가 많아 코드를 이어가는 것이 쉽지 않았는데, 변수 설정을 미리 계획하고 시작했다면, 조금 더 원활하게 진행할 수 있지 않았을까 하는 생각이 든다.

- 느낀 점
CNN과 마찬가지로 LLM 역시 기본 데이터가 가장 중요하다.
머신러닝에서 가장 중요한 것은 데이터다.

- 어려웠던 점
변수 설정과 새로 생성된 결과물을 컬럼에 정리하는 것을 체계적으로 계획하지 않아, 많이 헤매어서 힘들었다.

