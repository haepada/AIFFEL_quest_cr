# 위내시경 이미지 용종 검출 세그멘테이션 모델 비교 분석

이 프로젝트는 위내시경 이미지에서 용종을 검출하기 위한 다양한 세그멘테이션 모델을 구현하고 비교 분석한 연구입니다.

## 프로젝트 개요

의료 이미지 세그멘테이션은 질병 진단과 치료 계획 수립에 중요한 역할을 합니다. 이 연구에서는 위내시경 이미지에서 용종을 자동으로 검출하기 위한 세 가지 다른 딥러닝 모델 아키텍처를 구현하고 그 성능을 비교하였습니다.

## 학습 목표

- 위내시경 이미지에 용종을 표시한 데이터를 이용해 세그멘테이션 모델 구현
- 의료 이미지 특성상 제한된 데이터셋을 활용하기 위한 데이터 증강 기법 적용
- Encoder-Decoder, U-Net, VGG16 기반 U-Net 모델 구현 및 성능 비교
- U-Net에 사전 학습된 인코더를 적용하여 성능 개선 효과 분석

## 주요 내용

1. **데이터 전처리 및 증강**
   - 이미지 리사이징
   - 색조 조정, 수평 뒤집기, 이미지 이동 등의 증강 기법 적용
   - 학습/테스트 데이터 분할(8:2 비율)

2. **모델 구현**
   - **Encoder-Decoder 모델**: 기본적인 컨볼루션/디컨볼루션 구조
   - **U-Net 모델**: 스킵 커넥션을 활용한 U자형 구조
   - **VGG16 기반 U-Net 모델**: 사전 학습된 VGG16을 인코더로 활용

3. **모델 학습 및 평가**
   - 각 모델별 학습 수행 (배치 크기, 에포크 설정)
   - 손실 함수: BCE-Dice Loss (Binary Cross-Entropy + Dice Loss)
   - 평가 지표: Mean IoU, Dice Coefficient

4. **결과 시각화 및 분석**
   - 학습 그래프 시각화 (손실, 정확도 추이)
   - 예측 결과 시각화 (원본 이미지, 실제 마스크, 예측 마스크)
   - 세 모델의 성능 비교 분석

## 주요 결과

| 모델 | Mean IoU | 파라미터 수 | 특징 |
|------|----------|------------|------|
| Encoder-Decoder | 0.655 | 약 700만 | 경계 구분 부정확, 넓은 활성화 영역 |
| U-Net | 0.929 | 약 6,100만 | 정확한 경계 검출, 안정적 학습 패턴 |
| VGG16 기반 U-Net | 0.835 | 약 2,900만 | 대부분 정확하나 일부 케이스에서 오류 |

## 주요 발견

1. 스킵 커넥션이 있는 U-Net 계열 모델이 단순 Encoder-Decoder보다 우수한 성능을 보임
2. 예상과 달리 순수 U-Net이 사전 학습된 VGG16 기반 모델보다 더 높은 성능을 달성
3. 모델의 단순한 복잡성보다는 의료 이미지 도메인에 맞는 아키텍처 설계가 중요함

## 파일 구성

- `polyp_segmentation.ipynb`: 전체 실험 코드가 담긴 주피터 노트북
- `README.md`: 프로젝트 설명 및 사용 방법

## 결론

의료 이미지 세그멘테이션에는 단순히 복잡한 모델보다 도메인 특성에 맞춰 설계된 아키텍처가 더 효과적입니다. 
특히 U-Net의 스킵 커넥션 구조는 의료 이미지에서 중요한 경계 정보 보존에 탁월한 효과를 보여줍니다. 이러한 결과는 의료 영상 분석을 위한 딥러닝 모델 설계 시 중요한 지침을 제공합니다.
